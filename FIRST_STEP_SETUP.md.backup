# üöÄ Complete Guide - First Step: SAP IDoc Pipeline to Microsoft Fabric

## üìã First Step Overview

This first step establishes a complete SAP IDoc data ingestion pipeline to Microsoft Fabric:

```
[Python Simulator] ‚Üí [Azure Event Hub] ‚Üí [Fabric Eventstream] ‚Üí [KQL Database]
```

**Status: ‚úÖ COMPLETED**
- ‚úÖ Azure infrastructure deployed
- ‚úÖ Simulator tested and functional
- ‚úÖ Eventstream created and published
- ‚úÖ KQL Database operational
- ‚úÖ 605 messages successfully validated

---

## üéØ First Step Objective

Create a functional pipeline capable of:
1. **Generating** realistic SAP IDoc messages (5 types: ORDERS, WHSCON, DESADV, SHPMNT, INVOIC)
2. **Transmitting** these messages via Azure Event Hub
3. **Ingesting** data into Microsoft Fabric in real-time
4. **Analyzing** data with KQL (Kusto Query Language)

---

## üìê Architecture D√©ploy√©e

### Composants Azure
- **Tenant Event Hub** : `fthibault67gmail.onmicrosoft.com`
- **Event Hub Namespace** : `eh-idoc-flt8076.servicebus.windows.net`
- **Event Hub** : `idoc-events`
- **Consumer Group** : `fabric-consumer` (d√©di√© √† Fabric)

### Composants Microsoft Fabric
- **Tenant Fabric** : `MngEnvMCAP396311.onmicrosoft.com`
- **Workspace** : `SAP-IDoc-Fabric`
  - ID : `ad53e547-23dc-46b0-ab5f-2acbaf0eec64`
- **Eventhouse** : `kqldbsapidoc`
  - ID : `f91aaea3-7889-4415-851c-f4258a2fff6b`
  - Cluster URI : `https://trd-50gjamacvb06uc7dnr.z8.kusto.fabric.microsoft.com`
- **KQL Database** : `kqldbsapidoc` (auto-cr√©√© avec l'Eventhouse)
- **Data Connection** : `EventHub-idoc-events`
  - ID : `da4b9100-d350-463e-9761-bacc3b9c78f6`
- **Eventstream** : `SAPIdocIngest`
  - ID : `22c57137-e45f-4116-8b5b-e9849614bf17`

### Table KQL
- **Nom** : `idoc_raw`
- **Colonnes** : 9 colonnes optimis√©es pour auto-mapping
  - `idoc_type` (string)
  - `message_type` (string)
  - `sap_system` (string)
  - `timestamp` (datetime)
  - `control` (dynamic)
  - `data` (dynamic)
  - `EventProcessedUtcTime` (datetime)
  - `PartitionId` (string)
  - `EventEnqueuedUtcTime` (datetime)
- **Streaming ingestion** : Activ√©
- **R√©tention** : 90 jours

---

## üîß Pr√©requis

### Outils n√©cessaires
- [x] Python 3.11+
- [x] Azure CLI
- [x] PowerShell 7+
- [x] VS Code (optionnel mais recommand√©)
- [x] Git
- [x] uvx (pour MCP server)

### Comptes et acc√®s
- [x] Compte Azure avec souscription active
- [x] Acc√®s Microsoft Fabric avec capacit√© F64+
- [x] Permissions :
  - Azure Event Hubs Data Receiver (Event Hub)
  - Contributor (Workspace Fabric)

---

## üìù √âtapes de D√©ploiement de Z√©ro

### √âtape 1 : Cloner le Repository

```bash
git clone https://github.com/flthibau/Fabric-SAP-Idocs.git
cd Fabric-SAP-Idocs
```

### √âtape 2 : Configurer Azure Event Hub

#### 2.1 D√©ployer l'infrastructure

```powershell
# Se connecter √† Azure
az login

# Cr√©er Resource Group
az group create --name rg-idoc-fabric-dev --location westeurope

# Cr√©er Event Hub Namespace
az eventhubs namespace create \
  --name eh-idoc-flt8076 \
  --resource-group rg-idoc-fabric-dev \
  --location westeurope \
  --sku Standard

# Cr√©er Event Hub
az eventhubs eventhub create \
  --name idoc-events \
  --namespace-name eh-idoc-flt8076 \
  --resource-group rg-idoc-fabric-dev \
  --partition-count 4 \
  --message-retention 7

# Cr√©er Consumer Group pour Fabric
az eventhubs eventhub consumer-group create \
  --name fabric-consumer \
  --eventhub-name idoc-events \
  --namespace-name eh-idoc-flt8076 \
  --resource-group rg-idoc-fabric-dev
```

#### 2.2 Assigner les permissions RBAC

```powershell
# Obtenir votre User Principal ID
$userId = az ad signed-in-user show --query id -o tsv

# Assigner le r√¥le Azure Event Hubs Data Receiver
az role assignment create \
  --assignee $userId \
  --role "Azure Event Hubs Data Receiver" \
  --scope /subscriptions/<subscription-id>/resourceGroups/rg-idoc-fabric-dev/providers/Microsoft.EventHub/namespaces/eh-idoc-flt8076
```

### √âtape 3 : Configurer le Simulateur Python

#### 3.1 Cr√©er l'environnement virtuel

```powershell
cd simulator
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

#### 3.2 Configurer config.yaml

Cr√©er `simulator/config/config.yaml` :

```yaml
eventhub:
  connection_string: "Endpoint=sb://eh-idoc-flt8076.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=<YOUR_KEY>"
  name: "idoc-events"

sap:
  system: "S4HPRD"
  client: "100"

simulation:
  message_rate: 10
  batch_size: 100
  run_duration_seconds: 3600
```

> ‚ö†Ô∏è **Important** : Ce fichier est exclu du Git (.gitignore) car il contient des secrets.

#### 3.3 Tester le simulateur

```powershell
# Test avec 5 messages
python main.py --count 5
```

**R√©sultat attendu** :
```
Sending batch 1 with 5 messages...
Batch 1 sent successfully: 5 messages (19.6 KB) in 1.2s
Simulator stopped after reaching message count: 5
```

### √âtape 4 : Cr√©er le Workspace Fabric

1. Ouvrir [Microsoft Fabric Portal](https://app.fabric.microsoft.com)
2. Cr√©er un nouveau Workspace : **SAP-IDoc-Fabric**
3. Assigner une capacit√© F64+
4. Noter le Workspace ID (visible dans l'URL)

### √âtape 5 : Cr√©er l'Eventhouse et la KQL Database

#### Option 1 : Via l'interface Fabric (Recommand√©)

1. Dans le Workspace, cr√©er un **Eventhouse** : `kqldbsapidoc`
2. La KQL Database `kqldbsapidoc` sera automatiquement cr√©√©e
3. Noter l'Eventhouse ID et le Cluster URI

#### Option 2 : Via Azure CLI

```bash
fab mkdir "SAP-IDoc-Fabric.Workspace/kqldbsapidoc.Eventhouse"
```

### √âtape 6 : Cr√©er la Data Connection

1. Dans Fabric Portal ‚Üí Workspace `SAP-IDoc-Fabric`
2. Ouvrir l'Eventhouse `kqldbsapidoc`
3. **Data connections** ‚Üí **New connection**
4. S√©lectionner **Azure Event Hubs**
5. Configurer :
   - **Connection name** : `EventHub-idoc-events`
   - **Namespace** : `eh-idoc-flt8076.servicebus.windows.net`
   - **Event Hub** : `idoc-events`
   - **Consumer group** : `fabric-consumer`
   - **Authentication** : Organizational account (Entra ID)
6. **Create**
7. Noter le Data Connection ID (visible dans les d√©tails)

### √âtape 7 : Cr√©er l'Eventstream

#### Option 1 : Via l'interface Fabric

1. Dans le Workspace, cr√©er un **Eventstream** : `SAPIdocIngest`
2. Ajouter une **Source** : Azure Event Hub
   - Data Connection : `EventHub-idoc-events`
   - Consumer Group : `fabric-consumer`
3. Ajouter un **Stream** : Connecter source au stream
4. Ajouter une **Destination** : Eventhouse
   - Eventhouse : `kqldbsapidoc`
   - Database : `kqldbsapidoc`
   - Mode : **Direct ingestion**
   - Table : (√† cr√©er apr√®s publication)
5. **Publish**

#### Option 2 : Via script PowerShell (Hybride)

```powershell
cd fabric\eventstream
.\create-eventstream-hybrid.ps1 `
  -WorkspaceName "SAP-IDoc-Fabric" `
  -EventstreamName "SAPIdocIngest" `
  -EventhouseName "kqldbsapidoc" `
  -DataConnectionId "da4b9100-d350-463e-9761-bacc3b9c78f6"
```

**Ensuite, publier manuellement dans le Portal.**

### √âtape 8 : Installer et Configurer le MCP Server

#### 8.1 Installer uvx

```powershell
pip install uvx
```

#### 8.2 Configurer mcp.json

√âditer `%APPDATA%\Code\User\globalStorage\github.copilot\globalState\mcp.json` :

```json
{
  "mcpServers": {
    "fabric-rti": {
      "command": "uvx",
      "args": ["microsoft-fabric-rti-mcp"],
      "env": {
        "KUSTO_SERVICE_URI": "https://trd-50gjamacvb06uc7dnr.z8.kusto.fabric.microsoft.com",
        "KUSTO_SERVICE_DEFAULT_DB": "kqldbsapidoc"
      }
    }
  }
}
```

#### 8.3 Red√©marrer VS Code

```powershell
# Fermer VS Code compl√®tement, puis le relancer
```

### √âtape 9 : Cr√©er la Table KQL Optimis√©e

#### 9.1 Via MCP Server (GitHub Copilot dans VS Code)

Dans GitHub Copilot Chat :

```
Utilise le MCP server fabric-rti pour ex√©cuter le script recreate-idoc-table-optimized.kql
```

#### 9.2 Via copier-coller manuel

1. Ouvrir `fabric/warehouse/schema/recreate-idoc-table-optimized.kql`
2. Copier tout le contenu
3. Dans Fabric Portal ‚Üí KQL Database `kqldbsapidoc`
4. Ouvrir **Query**
5. Coller et **Run**

### √âtape 10 : Configurer la Destination Eventstream

1. Ouvrir l'Eventstream `SAPIdocIngest`
2. Mode **Live** (si pas d√©j√† actif)
3. Cliquer sur la destination Eventhouse
4. **Configure**
5. S√©lectionner la table : `idoc_raw`
6. **Save**

### √âtape 11 : Tester le Pipeline End-to-End

#### 11.1 Envoyer des messages

```powershell
cd simulator
python main.py --count 10
```

#### 11.2 Valider l'ingestion

Dans Fabric Portal ‚Üí KQL Database ‚Üí Query :

```kql
// Compter les messages
idoc_raw
| count

// Voir les derniers messages
idoc_raw
| top 10 by timestamp desc
| project timestamp, idoc_type, message_type, sap_system

// Distribution par type
idoc_raw
| summarize count() by message_type
| render piechart
```

**R√©sultat attendu** : Au moins 10 messages avec distribution correcte.

---

## ‚úÖ Validation de la Premi√®re √âtape

### Checklist de Validation

- [ ] Event Hub cr√©√© et accessible
- [ ] Consumer Group `fabric-consumer` existe
- [ ] Simulateur envoie des messages (test√© avec --count 5)
- [ ] Workspace Fabric cr√©√© avec capacit√© F64+
- [ ] Eventhouse et KQL Database cr√©√©s
- [ ] Data Connection cr√©√©e et configur√©e
- [ ] Eventstream cr√©√© et publi√©
- [ ] Table `idoc_raw` cr√©√©e avec 9 colonnes
- [ ] MCP server install√© et fonctionnel
- [ ] Messages arrivent dans la table KQL
- [ ] Toutes les colonnes sont popul√©es
- [ ] Queries KQL fonctionnent correctement

### R√©sultats de Validation Actuels

‚úÖ **Pipeline complet valid√© avec 605 messages** :
- WHSCON : 193 messages (32%)
- ORDERS : 144 messages (24%)
- DESADV : 127 messages (21%)
- SHPMNT : 92 messages (15%)
- INVOIC : 44 messages (7%)

‚úÖ **Toutes les colonnes popul√©es** :
- `idoc_type`, `message_type`, `sap_system`, `timestamp` : ‚úÖ
- `control`, `data` : ‚úÖ (objets JSON complets)
- `EventProcessedUtcTime`, `PartitionId`, `EventEnqueuedUtcTime` : ‚úÖ

---

## üìö Documentation de R√©f√©rence

### Fichiers Cl√©s

| Fichier | Description | Utilisation |
|---------|-------------|-------------|
| `README.md` | Vue d'ensemble du projet | Introduction g√©n√©rale |
| `FABRIC_QUICKSTART.md` | Guide rapide Fabric | Configuration Eventstream |
| `SESSION_SUMMARY.md` | R√©sum√© de la session de travail | Historique des √©tapes |
| `fabric/eventstream/HYBRID_APPROACH_GUIDE.md` | Automatisation Eventstream | Approche script + manuel |
| `fabric/warehouse/schema/recreate-idoc-table-optimized.kql` | Sch√©ma table optimis√© | Cr√©ation table KQL |
| `simulator/QUICKSTART.md` | Guide simulateur | Installation et test |
| `simulator/main.py` | Simulateur Python | Code principal |

### Scripts Utiles

| Script | Description |
|--------|-------------|
| `fabric/eventstream/create-eventstream-hybrid.ps1` | Cr√©er Eventstream via API |
| `fabric/warehouse/schema/recreate-idoc-table-optimized.kql` | Cr√©er table KQL optimis√©e |
| `fabric/warehouse/schema/validate-ingestion.kql` | Requ√™tes de validation |

### Configurations

| Fichier | Description | Statut |
|---------|-------------|--------|
| `simulator/config/config.yaml` | Config simulateur | ‚ö†Ô∏è Exclu du Git (secrets) |
| `.gitignore` | Prot√®ge les secrets | ‚úÖ √Ä jour |
| `mcp.json` | Config MCP server | ‚úÖ Configur√© |

---

## üîç Troubleshooting

### Probl√®me : Simulateur ne d√©marre pas

**Erreur** : `ImportError: No module named 'azure'`

**Solution** :
```powershell
cd simulator
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

### Probl√®me : Eventstream ne re√ßoit pas de donn√©es

**V√©rifications** :
1. Le consumer group est bien `fabric-consumer` (pas `$Default`)
2. Les permissions RBAC sont assign√©es
3. L'Eventstream est publi√©
4. Le simulateur envoie des messages : `python main.py --count 5`

### Probl√®me : Colonnes vides dans la table KQL

**Cause** : Noms de colonnes ne correspondent pas aux champs JSON

**Solution** : Utiliser le script `recreate-idoc-table-optimized.kql` qui cr√©e les colonnes avec les noms corrects (snake_case).

### Probl√®me : MCP server ne fonctionne pas

**V√©rifications** :
1. `mcp.json` est dans le bon dossier : `%APPDATA%\Code\User\globalStorage\github.copilot\globalState\`
2. VS Code a √©t√© compl√®tement red√©marr√© apr√®s la configuration
3. `uvx` est install√© : `uvx --version`
4. Les variables d'environnement sont correctes (Cluster URI, Database name)

---

## üéØ Prochaines √âtapes (Phases 2+)

### Phase 2 : Transformation et Enrichissement
- [ ] Cr√©er des materialized views pour agr√©gations
- [ ] Impl√©menter des transformations m√©tier
- [ ] Cr√©er tables Silver/Gold (architecture Medallion)

### Phase 3 : API GraphQL
- [ ] D√©finir sch√©ma GraphQL
- [ ] Impl√©menter resolvers
- [ ] D√©ployer sur Azure Container Apps

### Phase 4 : Gouvernance
- [ ] Int√©grer Microsoft Purview
- [ ] D√©finir r√®gles de qualit√© des donn√©es
- [ ] Cataloguer les assets

### Phase 5 : Visualisation
- [ ] Dashboard Power BI temps r√©el
- [ ] Alertes Data Activator
- [ ] Monitoring op√©rationnel

---

## üìû Support et Ressources

### Documentation Microsoft
- [Microsoft Fabric](https://learn.microsoft.com/fabric/)
- [Eventstream](https://learn.microsoft.com/fabric/real-time-intelligence/event-streams/overview)
- [KQL Database](https://learn.microsoft.com/fabric/real-time-intelligence/create-database)
- [KQL Query Language](https://learn.microsoft.com/azure/data-explorer/kusto/query/)

### Repository GitHub
- URL : `https://github.com/flthibau/Fabric-SAP-Idocs`
- Issues : Pour signaler des probl√®mes
- Discussions : Pour poser des questions

---

## üìä M√©triques de Succ√®s de la Premi√®re √âtape

| M√©trique | Cible | R√©sultat |
|----------|-------|----------|
| Messages envoy√©s | > 100 | ‚úÖ 605 |
| Taux de r√©ussite ingestion | > 99% | ‚úÖ 100% |
| Colonnes popul√©es | 9/9 | ‚úÖ 9/9 |
| Latence moyenne | < 5 min | ‚úÖ < 1 min |
| Requ√™tes KQL fonctionnelles | > 5 | ‚úÖ 10+ |

---

**‚ú® F√©licitations ! La premi√®re √©tape est compl√©t√©e avec succ√®s !**

*Date de validation : 2025* 
*Version : 1.0*
