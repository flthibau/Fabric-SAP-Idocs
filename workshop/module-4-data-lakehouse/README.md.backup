# Module 4: Data Lakehouse

> **Building the Gold layer in OneLake using mirrored Bronze/Silver data and Materialized Lake Views**

â±ï¸ **Duration**: 120 minutes | ğŸ¯ **Level**: Intermediate | ğŸ“‹ **Prerequisites**: Modules 1-3 completed

---

## ğŸ“– Module Overview

Implement the Gold layer of the medallion architecture in Microsoft Fabric Lakehouse. This module focuses on creating business-ready dimensional models using materialized lake views that query the automatically mirrored Bronze and Silver Delta tables from Eventhouse.

### Learning Objectives

- âœ… Understand medallion architecture with Eventhouse and Lakehouse integration
- âœ… Create Fabric Lakehouse and configure OneLake storage
- âœ… Understand OneLake mirroring from Eventhouse to Lakehouse
- âœ… Create Gold layer business views using materialized lake views
- âœ… Design star schema (dimensions and facts)
- âœ… Optimize Delta tables for query performance

---

## ğŸ“š Medallion Architecture in Fabric

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Bronze Layer (Raw) - EVENTHOUSE                    â”‚
â”‚  â€¢ Real-time IDoc data ingestion                    â”‚
â”‚  â€¢ KQL tables in Eventhouse                         â”‚
â”‚  â€¢ Auto-mirrored to Lakehouse as Delta tables       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“ KQL Update Policies (Real-Time)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Silver Layer (Cleansed) - EVENTHOUSE               â”‚
â”‚  â€¢ Parsed and normalized via KQL                    â”‚
â”‚  â€¢ Data quality checks                              â”‚
â”‚  â€¢ Real-time transformations                        â”‚
â”‚  â€¢ Auto-mirrored to Lakehouse as Delta tables       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“ Mirroring to OneLake
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mirrored Bronze/Silver - LAKEHOUSE                 â”‚
â”‚  â€¢ Automatic sync from Eventhouse                   â”‚
â”‚  â€¢ Delta Lake format                                â”‚
â”‚  â€¢ Available for analytics engines                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“ Materialized Lake Views
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Gold Layer (Business) - LAKEHOUSE                  â”‚
â”‚  â€¢ Dimensions & Facts                               â”‚
â”‚  â€¢ Materialized lake views                          â”‚
â”‚  â€¢ Star schema design                               â”‚
â”‚  â€¢ Optimized for queries                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Concept**: 
- **Bronze & Silver** layers reside in **Eventhouse** for real-time processing
- **Bronze & Silver** are automatically **mirrored** to **Lakehouse** as Delta tables via OneLake
- **Gold** layer is created in **Lakehouse** using **materialized lake views** that query the mirrored Silver Delta tables

---

## ğŸ§ª Hands-On Labs

### Lab 1: Create Lakehouse and Verify Mirroring

**Steps**:
1. Create Lakehouse: `lakehouse_3pl`
2. Configure OneLake storage
3. Verify Bronze and Silver tables from Eventhouse are mirrored
4. Create folder structure for Gold layer:
   ```
   /Files/gold/dimensions/
   /Files/gold/facts/
   ```

**Verify Mirroring**:
After setting up Eventhouse Bronze and Silver layers in Module 3, they should automatically appear in the Lakehouse as Delta tables via OneLake mirroring.

```sql
-- In Lakehouse SQL endpoint, verify mirrored tables
SHOW TABLES;

-- Should see:
-- bronze_idocs (mirrored from Eventhouse)
-- silver_shipments (mirrored from Eventhouse)
-- silver_orders (mirrored from Eventhouse)

-- Query mirrored Silver data
SELECT * FROM silver_shipments LIMIT 10;
SELECT * FROM silver_orders LIMIT 10;
```

---

### Lab 2: Understand OneLake Mirroring

**What is OneLake Mirroring?**

OneLake provides automatic, continuous replication of Eventhouse tables to Lakehouse as Delta tables. This enables:
- âœ… Real-time data in Eventhouse (KQL queries)
- âœ… Analytics-ready data in Lakehouse (Spark, SQL, Power BI)
- âœ… No manual ETL needed
- âœ… Single source of truth via OneLake

**Configuration** (typically automatic, no code needed):
The mirroring happens automatically when both Eventhouse and Lakehouse are in the same workspace and OneLake.


---

### Lab 3: Build Gold Layer - Dimension Tables
        current_timestamp().alias("created_timestamp")
    ) \
    .filter(col("shipment_id").isNotNull())

# Data quality score
silver_df = silver_df.withColumn(
    "data_quality_score",
    when(col("customer_id").isNotNull() & col("carrier_id").isNotNull(), 1.0)
    .when(col("customer_id").isNotNull() | col("carrier_id").isNotNull(), 0.8)
    .otherwise(0.5)
)

# Upsert to Silver table
silver_table = DeltaTable.forName(spark, "lakehouse_3pl.silver_shipments")

silver_table.alias("target").merge(
    silver_df.alias("source"),
    "target.shipment_id = source.shipment_id"
).whenMatchedUpdateAll() \
 .whenNotMatchedInsertAll() \
 .execute()

print(f"Processed {silver_df.count()} shipment records")
```

**Create Silver Tables**:

```sql
-- Shipments
CREATE TABLE silver_shipments (
    shipment_id STRING PRIMARY KEY,
    shipment_number STRING,
    customer_id STRING,
    customer_name STRING,
    carrier_id STRING,
    ship_date DATE,
    delivery_date DATE,
    origin_location STRING,
    destination_location STRING,
    total_weight DECIMAL(18,2),
    status STRING,
    data_quality_score DECIMAL(3,2),
    source_idoc_number STRING,
    created_timestamp TIMESTAMP,
    modified_timestamp TIMESTAMP
)
USING DELTA
PARTITIONED BY (ship_date);

-- Orders
CREATE TABLE silver_orders (
    order_id STRING PRIMARY KEY,
    order_number STRING,
    customer_id STRING,
    order_date DATE,
    total_value DECIMAL(18,2),
    status STRING,
    created_timestamp TIMESTAMP
)
USING DELTA
PARTITIONED BY (order_date);
```

---

### Lab 4: Build Gold Layer

**Create Dimensions**:

```sql
-- Dimension: Customer
CREATE TABLE gold_dim_customer (
    customer_key INT GENERATED ALWAYS AS IDENTITY,
    customer_id STRING,
    customer_name STRING,
    customer_type STRING,
    region STRING,
    valid_from DATE,
    valid_to DATE,
    is_current BOOLEAN
)
USING DELTA;

-- Dimension: Carrier
CREATE TABLE gold_dim_carrier (
    carrier_key INT GENERATED ALWAYS AS IDENTITY,
    carrier_id STRING,
    carrier_name STRING,
    service_type STRING,
    is_current BOOLEAN
)
USING DELTA;
```

**Create Facts**:

```sql
-- Fact: Shipments
CREATE TABLE gold_fact_shipment (
    shipment_key BIGINT GENERATED ALWAYS AS IDENTITY,
    shipment_id STRING,
    customer_key INT,
    carrier_key INT,
    ship_date_key INT,
    delivery_date_key INT,
    total_weight DECIMAL(18,2),
    total_value DECIMAL(18,2),
    on_time_delivery_flag BOOLEAN,
    delivery_delay_days INT,
    created_timestamp TIMESTAMP,
    FOREIGN KEY (customer_key) REFERENCES gold_dim_customer(customer_key),
    FOREIGN KEY (carrier_key) REFERENCES gold_dim_carrier(carrier_key)
)
USING DELTA
PARTITIONED BY (ship_date_key);
```

**Aggregation View**:

```sql
-- Materialized view for daily shipment summary
CREATE OR REPLACE VIEW gold_shipments_daily_summary AS
SELECT 
    ship_date,
    customer_id,
    carrier_id,
    COUNT(*) as shipment_count,
    SUM(total_weight) as total_weight,
    SUM(total_value) as total_value,
    SUM(CASE WHEN on_time_delivery_flag THEN 1 ELSE 0 END) as on_time_count,
    ROUND(100.0 * SUM(CASE WHEN on_time_delivery_flag THEN 1 ELSE 0 END) / COUNT(*), 2) as on_time_rate
FROM gold_fact_shipment f
JOIN gold_dim_customer c ON f.customer_key = c.customer_key
JOIN gold_dim_carrier cr ON f.carrier_key = cr.carrier_key
GROUP BY ship_date, customer_id, carrier_id;
```

---

### Lab 5: Optimize Delta Tables

**Optimization Commands**:

```sql
-- Optimize with Z-Ordering
OPTIMIZE silver_shipments
ZORDER BY (customer_id, ship_date);

OPTIMIZE gold_fact_shipment
ZORDER BY (customer_key, ship_date_key);

-- Vacuum old versions (retain 7 days)
VACUUM silver_shipments RETAIN 168 HOURS;
VACUUM gold_fact_shipment RETAIN 168 HOURS;

-- Table statistics
ANALYZE TABLE silver_shipments COMPUTE STATISTICS;
ANALYZE TABLE gold_fact_shipment COMPUTE STATISTICS FOR ALL COLUMNS;
```

**Schedule Optimization**:

```python
# In Spark notebook - schedule daily
from pyspark.sql.functions import current_date

def optimize_tables():
    tables = [
        "silver_shipments",
        "silver_orders", 
        "gold_fact_shipment"
    ]
    
    for table in tables:
        print(f"Optimizing {table}...")
        spark.sql(f"OPTIMIZE lakehouse_3pl.{table}")
        spark.sql(f"VACUUM lakehouse_3pl.{table} RETAIN 168 HOURS")

# Run daily via Fabric Pipeline
optimize_tables()
```

---

### Lab 6: Configure OneLake Shortcuts

**Create Shortcuts to Eventhouse**:

```python
# Python API to create shortcuts
import requests

def create_onelake_shortcut(
    workspace_id,
    lakehouse_id,
    shortcut_name,
    target_path,
    target_type="Eventhouse"
):
    url = f"https://api.fabric.microsoft.com/v1/workspaces/{workspace_id}/items/{lakehouse_id}/shortcuts"
    
    payload = {
        "name": shortcut_name,
        "path": "Files/shortcuts",
        "target": {
            "type": target_type,
            "path": target_path
        }
    }
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    response = requests.post(url, json=payload, headers=headers)
    return response.json()

# Create shortcut to real-time data
create_onelake_shortcut(
    workspace_id="<workspace-id>",
    lakehouse_id="<lakehouse-id>",
    shortcut_name="realtime_shipments",
    target_path="/databases/idoc_realtime/tables/idoc_raw",
    target_type="Eventhouse"
)
```

---

## ğŸ“‹ Best Practices

**Bronze Layer**:
- âœ… Keep raw data as-is for audit trail
- âœ… Partition by ingestion date and type
- âœ… Use JSON or Parquet for flexibility

**Silver Layer**:
- âœ… Implement data quality checks
- âœ… Deduplicate records
- âœ… Normalize data structure
- âœ… Use Delta Lake for ACID guarantees

**Gold Layer**:
- âœ… Design for query performance
- âœ… Use star/snowflake schema
- âœ… Create materialized aggregations
- âœ… Optimize with Z-Ordering

**Delta Table Management**:
- âœ… Regular OPTIMIZE operations
- âœ… VACUUM old versions
- âœ… Update table statistics
- âœ… Monitor table sizes

---

## âœ… Module Completion

**Summary**: Built complete medallion architecture with Bronze/Silver/Gold layers using Delta Lake

**Next**: [Module 5: Security & Governance](../module-5-security-governance/README.md) - Implement RLS and Purview integration

---

**[â† Module 3](../module-3-real-time-intelligence/README.md)** | **[Home](../README.md)** | **[Module 5 â†’](../module-5-security-governance/README.md)**
