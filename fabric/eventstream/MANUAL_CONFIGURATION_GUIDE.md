# Guide de configuration manuelle de l'Eventstream

## üéØ Objectif
Configurer l'Eventstream `SAPIdocIngest` dans le portail Fabric pour capturer le sch√©ma JSON exact des sources et destinations.

---

## üìã Informations n√©cessaires

### Azure Event Hub (Source)
- **Namespace** : `eh-idoc-flt8076.servicebus.windows.net`
- **Event Hub** : `idoc-events`
- **Consumer Group** : `fabric-consumer`
- **Resource Group** : `rg-idoc-fabric-dev`
- **Subscription** : Votre subscription Azure

### Fabric Resources (Destination)
- **Workspace** : `SAP-IDoc-Fabric`
  - ID : `ad53e547-23dc-46b0-ab5f-2acbaf0eec64`
- **Eventstream** : `SAPIdocIngest`
  - ID : `cb23a2a2-ad04-4b46-9616-d76e59a9a665`
- **Eventhouse** : `kqldbsapidoc_auto`
- **KQL Database** : `kqldbsapidoc`

---

## üöÄ √âtapes de configuration

### √âTAPE 1 : Ouvrir le portail Fabric

1. Ouvrir votre navigateur : https://app.fabric.microsoft.com
2. Se connecter avec votre compte Microsoft
3. Cliquer sur l'ic√¥ne **Workspaces** dans le menu de gauche
4. S√©lectionner **SAP-IDoc-Fabric**

### √âTAPE 2 : Ouvrir l'Eventstream

1. Dans la liste des items, trouver **SAPIdocIngest** (type : Eventstream)
2. Cliquer dessus pour l'ouvrir
3. Vous devriez voir un canvas vide avec le message "Add source"

### √âTAPE 3 : Activer le mode Edit

1. En haut √† droite, cliquer sur **Edit** pour passer en mode √©dition
2. Le canvas devrait afficher les options d'ajout de source

### √âTAPE 4 : Ajouter la source Azure Event Hub

#### 4.1 Lancer le wizard
1. Cliquer sur **Add source** dans le ribbon (ou sur la carte "Add source" dans le canvas)
2. Dans le menu d√©roulant, s√©lectionner **Azure Event Hubs**
3. Le wizard "Connect" s'ouvre

#### 4.2 Cr√©er une nouvelle connection

1. Sur la page **Connect**, confirmer que **Basic** est s√©lectionn√© pour "Feature level"
2. Cliquer sur **New connection**

#### 4.3 Connection settings

Dans la section **Connection settings** :
- **Event Hubs namespace** : `eh-idoc-flt8076.servicebus.windows.net`
- **Event hub** : `idoc-events`

#### 4.4 Connection credentials

**OPTION A - Shared Access Key (Plus simple pour le test)** :

1. **Connection name** : `eh-sap-idoc-connection`
2. **Authentication kind** : S√©lectionner **Shared Access Key**
3. **Shared Access Key Name** : R√©cup√©rer depuis Azure :
   ```powershell
   # Dans un terminal PowerShell
   az eventhubs eventhub authorization-rule keys list `
     --resource-group rg-idoc-fabric-dev `
     --namespace-name eh-idoc-flt8076 `
     --eventhub-name idoc-events `
     --name simulator-send `
     --query primaryKey -o tsv
   ```
4. **Shared Access Key** : Coller la cl√© r√©cup√©r√©e
5. Cliquer sur **Connect** en bas de la page

**OPTION B - Entra ID (Recommand√© pour production)** :

1. **Connection name** : `eh-sap-idoc-connection-entra`
2. **Authentication kind** : S√©lectionner **Organizational account** ou **Managed Identity**
3. Se connecter avec votre compte Azure
4. Cliquer sur **Connect**

‚ö†Ô∏è **Note** : Si vous utilisez Entra ID, vous devrez peut-√™tre accorder des permissions RBAC sur l'Event Hub.

#### 4.5 Stream details

1. **Consumer group** : `fabric-consumer`
2. **Data format** : S√©lectionner **JSON**
3. **Source name** (optionnel) : Garder le nom par d√©faut ou renommer en `EventHub-SAP-IDocs`
4. Cliquer sur **Next**

#### 4.6 Review + connect

1. V√©rifier tous les param√®tres
2. Cliquer sur **Add**
3. La source Event Hub est ajout√©e au canvas

### √âTAPE 5 : Ajouter la destination KQL Database

#### 5.1 Lancer le wizard de destination

1. Dans le ribbon, cliquer sur **Add destination**
2. S√©lectionner **Eventhouse**

#### 5.2 Configuration de base

1. **Ingestion mode** : S√©lectionner **Direct ingestion**
2. **Destination name** : `KQL-SAP-Analysis`
3. **Workspace** : S√©lectionner **SAP-IDoc-Fabric** (devrait √™tre pr√©s√©lectionn√©)
4. **Eventhouse** : S√©lectionner **kqldbsapidoc_auto**

‚ö†Ô∏è **Important** : NE PAS cocher "Activate ingestion after adding the data source" pour l'instant

5. Cliquer sur **Save**

#### 5.3 Connecter le flux

1. La destination appara√Æt sur le canvas
2. Si elle n'est pas automatiquement connect√©e, glisser une connexion depuis la sortie de `EventHub-SAP-IDocs` vers l'entr√©e de `KQL-SAP-Analysis`
3. V√©rifier que le flux est bien connect√© (ligne entre les deux n≈ìuds)

### √âTAPE 6 : Publier l'Eventstream

1. Dans le ribbon, cliquer sur **Publish**
2. Confirmer la publication
3. Attendre quelques secondes pour que l'Eventstream passe en mode **Live view**

### √âTAPE 7 : Configurer la table KQL Database

#### 7.1 Ouvrir la configuration de destination

1. En mode **Live view**, dans le n≈ìud destination `KQL-SAP-Analysis`, cliquer sur **Configure**
2. La fen√™tre "Get data" de l'Eventhouse s'ouvre

#### 7.2 Cr√©er la table

1. **Select a table** : S√©lectionner **New table**
2. **Table name** : `idoc_raw`
3. **Data connection name** : Garder le nom propos√© (ex: `es-sap-idoc-connection`)
4. Cliquer sur **Next**

‚è±Ô∏è Attendre quelques instants pendant que Fabric r√©cup√®re des donn√©es d'exemple depuis l'Event Hub.

#### 7.3 Inspecter et mapper les donn√©es

1. Sur l'√©cran **Inspect the data** :
   - **Format** : Confirmer **JSON**
   - Cliquer sur **Edit columns**

2. Dans **Edit columns** :
   - Fabric devrait d√©tecter automatiquement la structure JSON
   - Si n√©cessaire, ajuster le mapping :
     - `idoc_type` : string
     - `message_type` : string
     - `sap_system` : string
     - `timestamp` : datetime
     - `control` : dynamic (objet JSON)
     - `data` : dynamic (objet JSON)
   - Cliquer sur **Apply**

3. Cliquer sur **Finish**

#### 7.4 R√©sum√©

1. Sur l'√©cran **Summary**, v√©rifier :
   - ‚úÖ Table `idoc_raw` cr√©√©e
   - ‚úÖ Connection √©tablie entre Eventstream et Eventhouse
   - ‚úÖ Sch√©ma mapp√©
2. Cliquer sur **Close**

### √âTAPE 8 : V√©rification

#### 8.1 V√©rifier le flux en Live view

1. Vous devriez voir :
   - Source `EventHub-SAP-IDocs` en vert
   - Destination `KQL-SAP-Analysis` en vert
   - Connexion entre les deux

#### 8.2 Tester avec des donn√©es

1. Ouvrir un terminal PowerShell
2. Lancer le simulateur :
   ```powershell
   cd c:\Users\flthibau\Desktop\Fabric+SAP+Idocs\simulator
   python main.py
   ```
3. Le simulateur devrait envoyer 100 messages IDoc

#### 8.3 V√©rifier dans Eventstream Data Preview

1. Dans l'Eventstream, cliquer sur le n≈ìud **EventHub-SAP-IDocs**
2. En bas, onglet **Data preview**
3. Vous devriez voir les messages JSON qui arrivent en temps r√©el

#### 8.4 V√©rifier dans KQL Database

1. Ouvrir le **KQL Queryset** ou **KQL Database** dans Fabric
2. Ex√©cuter la requ√™te :
   ```kql
   idoc_raw
   | take 10
   ```
3. Vous devriez voir les 10 premiers messages IDoc

---

## ‚úÖ Configuration termin√©e !

Votre Eventstream est maintenant compl√®tement configur√© et op√©rationnel.

**Prochaine √©tape** : Exporter la configuration pour l'automatisation

```powershell
fab export "SAP-IDoc-Fabric.Workspace/SAPIdocIngest.Eventstream" -o ".\fabric\eventstream\configured" -f
```

---

## üîß D√©pannage

### Probl√®me : "Unable to connect to Event Hub"
- V√©rifier que le namespace et event hub existent dans Azure
- V√©rifier les permissions si vous utilisez Entra ID
- Essayer avec Shared Access Key pour tester

### Probl√®me : "No data preview available"
- V√©rifier que l'Event Hub contient des messages (lancer le simulateur)
- V√©rifier que le consumer group `fabric-consumer` existe
- Attendre quelques minutes apr√®s la publication

### Probl√®me : "Table creation failed"
- V√©rifier que le KQL Database `kqldbsapidoc` existe
- V√©rifier les permissions sur l'Eventhouse
- Essayer de cr√©er la table manuellement :
  ```kql
  .create table idoc_raw (
      idoc_type: string,
      message_type: string,
      sap_system: string,
      timestamp: datetime,
      control: dynamic,
      data: dynamic
  )
  ```

---

## üìä R√©sultat attendu

Apr√®s cette configuration manuelle, vous aurez :
- ‚úÖ Eventstream `SAPIdocIngest` configur√© et publi√©
- ‚úÖ Source Event Hub connect√©e avec authentification
- ‚úÖ Destination KQL Database avec table `idoc_raw`
- ‚úÖ Flux de donn√©es actif : Event Hub ‚Üí Eventstream ‚Üí KQL Database
- ‚úÖ **Sch√©ma JSON captur√©** pour l'automatisation future

‚è±Ô∏è **Temps total estim√©** : 15-20 minutes
