# Configuration Eventstream dans Microsoft Fabric

## Vue d'ensemble

Ce guide vous aide Ã  configurer un Eventstream dans Microsoft Fabric Real-Time Intelligence pour capturer les messages IDoc depuis Azure Event Hub.

## PrÃ©requis

- âœ… Event Hub dÃ©ployÃ© et opÃ©rationnel (`eh-idoc-flt8076/idoc-events`)
- âœ… Messages IDoc envoyÃ©s avec succÃ¨s (100 messages testÃ©s)
- âœ… Workspace Microsoft Fabric avec capacitÃ© activÃ©e
- âœ… Permissions : Contributor sur Fabric workspace + Event Hubs Data Receiver sur Event Hub

## Ã‰tape 1 : CrÃ©er l'Eventstream

### 1.1 Dans Microsoft Fabric

1. Ouvrez votre workspace Fabric
2. Cliquez sur **+ New** â†’ **Real-Time Intelligence** â†’ **Eventstream**
3. Nommez l'Eventstream : `evs-sap-idoc-ingest`
4. Cliquez sur **Create**

### 1.2 Configuration de la source Event Hub

1. Dans le canvas Eventstream, cliquez sur **Add source**
2. SÃ©lectionnez **Azure Event Hubs**
3. Configurez la connexion :

   **ParamÃ¨tres de connexion :**
   ```
   Connection name: conn-eventhub-idoc
   Authentication kind: Organizational account (Entra ID)
   
   Event Hub namespace: eh-idoc-flt8076.servicebus.windows.net
   Event Hub: idoc-events
   Consumer group: $Default (ou crÃ©ez fabric-consumer)
   ```

4. Testez la connexion
5. Cliquez sur **Next**

### 1.3 Configuration du format de donnÃ©es

1. **Data format** : JSON
2. **Schema preview** : Laissez Fabric dÃ©tecter automatiquement le schema
3. VÃ©rifiez que les champs suivants sont dÃ©tectÃ©s :
   - `idoc_type` (string)
   - `message_type` (string)
   - `sap_system` (string)
   - `timestamp` (datetime/string)
   - `control` (object)
   - `data` (object)

4. Cliquez sur **Create source**

## Ã‰tape 2 : CrÃ©er le Consumer Group (RecommandÃ©)

Pour Ã©viter les conflits avec le CLI reader, crÃ©ez un consumer group dÃ©diÃ© :

```bash
az eventhubs eventhub consumer-group create \
  --resource-group rg-idoc-fabric-dev \
  --namespace-name eh-idoc-flt8076 \
  --eventhub-name idoc-events \
  --name fabric-consumer
```

Puis mettez Ã  jour la source Eventstream pour utiliser `fabric-consumer`.

## Ã‰tape 3 : Assigner les permissions RBAC

Fabric nÃ©cessite le rÃ´le Data Receiver sur Event Hub :

### Option A : Via le portail Azure

1. Allez dans Azure Portal â†’ Event Hub `idoc-events`
2. **Access Control (IAM)** â†’ **Add role assignment**
3. RÃ´le : **Azure Event Hubs Data Receiver**
4. Assignez Ã  : Votre identitÃ© Fabric ou Managed Identity du workspace

### Option B : Via Azure CLI

```bash
# RÃ©cupÃ©rer l'Object ID de votre compte
az ad signed-in-user show --query id -o tsv

# Assigner le rÃ´le
az role assignment create \
  --assignee <object-id> \
  --role "Azure Event Hubs Data Receiver" \
  --scope "/subscriptions/f79d4407-99c6-4d64-88fc-848fb05d5476/resourceGroups/rg-idoc-fabric-dev/providers/Microsoft.EventHub/namespaces/eh-idoc-flt8076/eventhubs/idoc-events"
```

## Ã‰tape 4 : Ajouter une destination

### Option 1 : KQL Database (RecommandÃ© pour l'analyse)

1. Dans le canvas Eventstream, cliquez sur la sortie
2. **Add destination** â†’ **KQL Database**
3. CrÃ©ez ou sÃ©lectionnez une base de donnÃ©es : `kqldb-sap-idoc`
4. CrÃ©ez une table : `idoc_raw`
5. Mapping de colonnes :
   ```
   - idoc_type â†’ string
   - message_type â†’ string
   - sap_system â†’ string
   - timestamp â†’ datetime
   - control â†’ dynamic
   - data â†’ dynamic
   ```

### Option 2 : Lakehouse (Pour le stockage long terme)

1. **Add destination** â†’ **Lakehouse**
2. SÃ©lectionnez ou crÃ©ez un Lakehouse : `lh-sap-idoc`
3. Table : `idoc_events`
4. Write mode : **Append**

### Option 3 : Reflex (Pour les alertes temps rÃ©el)

1. **Add destination** â†’ **Reflex**
2. CrÃ©ez des triggers basÃ©s sur :
   - Erreurs dans les IDocs (status != "03")
   - Volume de messages anormal
   - Messages avec exceptions

## Ã‰tape 5 : Configurer les transformations (Optionnel)

Avant d'envoyer vers la destination, ajoutez des transformations :

### 5.1 Ajouter des colonnes calculÃ©es

1. Cliquez sur **Transform** dans le canvas
2. Ajoutez des colonnes :
   ```sql
   -- Extraire le type de document
   doc_type = CASE 
     WHEN idoc_type = 'ORDERS05' THEN 'Purchase Order'
     WHEN idoc_type = 'WHSCON01' THEN 'Warehouse Confirmation'
     WHEN idoc_type = 'DESADV01' THEN 'Delivery Note'
     WHEN idoc_type = 'SHPMNT05' THEN 'Shipment'
     WHEN idoc_type = 'INVOIC02' THEN 'Invoice'
     ELSE 'Unknown'
   END
   
   -- Extraire le numÃ©ro de document du control
   document_number = control.docnum
   
   -- Date de crÃ©ation
   created_date = control.credat
   
   -- Statut du document
   document_status = control.status
   ```

### 5.2 Filtrer les messages (si nÃ©cessaire)

```sql
-- Ne garder que les messages avec statut valide
WHERE control.status IN ('03', '30', '31')

-- Exclure les messages de test
WHERE sap_system != 'TESTENV'
```

## Ã‰tape 6 : Activer et tester

1. Cliquez sur **Publish** pour activer l'Eventstream
2. Lancez le simulateur pour envoyer des messages :
   ```bash
   cd simulator
   python main.py
   ```

3. VÃ©rifiez dans Fabric :
   - **Data preview** dans Eventstream (vue temps rÃ©el)
   - RequÃªte KQL Database :
     ```kql
     idoc_raw
     | take 10
     | order by timestamp desc
     ```

## Ã‰tape 7 : Monitoring et mÃ©triques

### Dans l'Eventstream

- **Metrics** : Messages reÃ§us, erreurs, latence
- **Logs** : Erreurs de connexion, parsing

### RequÃªtes KQL utiles

```kql
// Volume par type d'IDoc (derniÃ¨re heure)
idoc_raw
| where timestamp > ago(1h)
| summarize count() by message_type
| render columnchart

// Latence moyenne
idoc_raw
| where timestamp > ago(1h)
| extend ingestion_time = ingestion_time()
| extend latency_seconds = datetime_diff('second', ingestion_time, todatetime(timestamp))
| summarize avg(latency_seconds) by bin(timestamp, 5m)
| render timechart

// Erreurs (statut != 03)
idoc_raw
| where control.status != "03"
| project timestamp, idoc_type, message_type, status=control.status, docnum=control.docnum
| order by timestamp desc
```

## Architecture finale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Simulateur     â”‚â”€â”€â”€â”€â”€â–¶â”‚  Event Hub       â”‚â”€â”€â”€â”€â”€â–¶â”‚  Eventstream    â”‚
â”‚  Python         â”‚      â”‚  idoc-events     â”‚      â”‚  (Fabric RTI)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                             â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚                                            â”‚
                              â–¼                                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  KQL Database   â”‚                        â”‚   Lakehouse      â”‚
                     â”‚  (Analyse RTI)  â”‚                        â”‚   (Stockage LT)  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Troubleshooting

### Erreur : "Cannot connect to Event Hub"
- VÃ©rifiez les permissions RBAC (Data Receiver)
- VÃ©rifiez que le namespace est correct
- Testez avec le CLI reader : `python read_eventhub.py --max 1`

### Pas de donnÃ©es dans l'Eventstream
- VÃ©rifiez que le simulateur envoie des messages
- VÃ©rifiez le consumer group (utilisez un diffÃ©rent du CLI)
- Regardez les mÃ©triques dans Event Hub (portail Azure)

### Erreurs de parsing JSON
- VÃ©rifiez le format de donnÃ©es dans la source (doit Ãªtre JSON)
- Testez un message avec `python read_eventhub.py --max 1 --details`

## Prochaines Ã©tapes

1. âœ… Configurer l'Eventstream (ce guide)
2. ğŸ“Š CrÃ©er des vues et agrÃ©gations dans KQL Database
3. ğŸ“ˆ CrÃ©er des tableaux de bord Power BI temps rÃ©el
4. ğŸ”” Configurer des alertes avec Reflex
5. ğŸ—„ï¸ Archiver les donnÃ©es dans Lakehouse
6. ğŸ”„ ImplÃ©menter la transformation des donnÃ©es (si nÃ©cessaire)
