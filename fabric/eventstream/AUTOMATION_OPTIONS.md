# Options d'automatisation pour Eventstream Fabric

## üéØ Objectif
Automatiser la configuration de l'Eventstream `SAPIdocIngest` avec :
- **Source** : Azure Event Hub (`eh-idoc-flt8076.servicebus.windows.net/idoc-events`)
- **Destination** : KQL Database (`kqldbsapidoc`)

---

## ‚úÖ Option 1: API REST Fabric (Recommand√©e)

### Principe
Utiliser l'API `POST /workspaces/{workspaceId}/eventstreams/{eventstreamId}/updateDefinition` pour mettre √† jour la d√©finition JSON de l'Eventstream.

### Avantages
- ‚úÖ **100% automatisable** via script
- ‚úÖ Utilise l'API officielle Fabric REST
- ‚úÖ Peut √™tre int√©gr√© dans CI/CD pipelines
- ‚úÖ Versionnable avec Git (d√©finition en JSON)

### Limitations
- ‚ö†Ô∏è **Sch√©ma JSON non document√©** : Fabric ne publie pas le sch√©ma complet pour sources/destinations
- ‚ö†Ô∏è **Complexit√©** : Requiert de l'ing√©nierie inverse pour trouver le format exact
- ‚ö†Ô∏è **Risque de breaking changes** : Le sch√©ma peut √©voluer sans pr√©avis

### Impl√©mentation

#### 1. Exporter un Eventstream configur√© manuellement
```powershell
# Configurer manuellement un Eventstream dans le portail
# Puis exporter pour analyser le format JSON

fab export "SAP-IDoc-Fabric.Workspace/SAPIdocIngest.Eventstream" -o ".\fabric\eventstream" -f
```

#### 2. Analyser la structure JSON
```bash
# Fichiers export√©s :
# - eventstream.json          # Sources, destinations, operators
# - eventstreamProperties.json # Retention, throughput
# - .platform                  # Metadata
```

#### 3. Cr√©er la d√©finition programmati quement
Le script `configure-eventstream.ps1` encode les 3 fichiers en Base64 et appelle l'API :

```powershell
POST https://api.fabric.microsoft.com/v1/workspaces/{workspaceId}/eventstreams/{eventstreamId}/updateDefinition

{
  "definition": {
    "parts": [
      {
        "path": "eventstream.json",
        "payload": "<base64>",
        "payloadType": "InlineBase64"
      },
      {
        "path": "eventstreamProperties.json",
        "payload": "<base64>",
        "payloadType": "InlineBase64"
      },
      {
        "path": ".platform",
        "payload": "<base64>",
        "payloadType": "InlineBase64"
      }
    ]
  }
}
```

#### 4. Ex√©cuter le script
```powershell
.\fabric\eventstream\configure-eventstream.ps1
```

### ‚ö†Ô∏è Pr√©requis
1. Configurer **manuellement** un Eventstream template avec Event Hub ‚Üí KQL DB
2. L'exporter avec `fab export` pour capturer le sch√©ma JSON exact
3. Adapter le script avec les valeurs correctes

### üìö Documentation API
- [Update Eventstream Definition](https://learn.microsoft.com/en-us/rest/api/fabric/eventstream/items/update-eventstream-definition)
- [Get Eventstream Definition](https://learn.microsoft.com/en-us/rest/api/fabric/eventstream/items/get-eventstream-definition)

---

## ‚úÖ Option 2: Fabric CLI Import/Export (Semi-automatique)

### Principe
1. Configurer un Eventstream **template** manuellement dans le portail
2. L'exporter avec `fab export`
3. Modifier les valeurs (workspace, database, etc.) dans les JSON
4. R√©importer avec `fab import`

### Avantages
- ‚úÖ Utilise le CLI Fabric officiel
- ‚úÖ Pas de manipulation d'API REST directe
- ‚úÖ Format JSON valid√© par Fabric

### Limitations
- ‚ö†Ô∏è N√©cessite un template configur√© manuellement au pr√©alable
- ‚ö†Ô∏è Modification manuelle des JSON export√©s
- ‚ö†Ô∏è Moins scriptable que l'API REST

### Impl√©mentation

#### 1. Cr√©er un template manuellement
Dans le portail Fabric :
1. Cr√©er un Eventstream "Template"
2. Ajouter source Event Hub avec Entra ID auth
3. Ajouter destination KQL Database
4. Publisher

#### 2. Exporter le template
```powershell
fab export "SAP-IDoc-Fabric.Workspace/Template.Eventstream" -o ".\templates" -f
```

#### 3. Modifier les JSON
√âditer `templates/Template.Eventstream/eventstream.json` :
- Remplacer les valeurs Event Hub namespace, hub name, consumer group
- Remplacer le nom de la KQL Database et table

#### 4. Importer dans un nouvel Eventstream
```powershell
# M√©thode 1: Cr√©er nouveau
fab mkdir "SAP-IDoc-Fabric.Workspace/SAPIdocIngest.Eventstream"

# M√©thode 2: Importer la d√©finition
fab import "SAP-IDoc-Fabric.Workspace/SAPIdocIngest.Eventstream" -i ".\templates\Template.Eventstream" -f
```

### üìö Documentation
- [Fabric CLI Import](https://microsoft.github.io/fabric-cli/commands/fs/import/)
- [Fabric CLI Export](https://microsoft.github.io/fabric-cli/commands/fs/export/)

---

## ‚ö†Ô∏è Option 3: Configuration manuelle dans le portail

### Principe
Configuration compl√®te via l'interface graphique du portail Fabric.

### Avantages
- ‚úÖ Interface visuelle guid√©e
- ‚úÖ Validation en temps r√©el
- ‚úÖ Pas de risque d'erreur de syntaxe JSON
- ‚úÖ Data preview disponible imm√©diatement

### Limitations
- ‚ùå **Pas automatisable**
- ‚ùå Pas de versioning
- ‚ùå Processus manuel r√©p√©titif pour plusieurs environnements

### √âtapes

#### 1. Ouvrir l'Eventstream
1. Naviguer vers https://app.fabric.microsoft.com
2. Workspace : `SAP-IDoc-Fabric`
3. Ouvrir `SAPIdocIngest`

#### 2. Ajouter la source Event Hub
1. Mode Edit ‚Üí `Add source` ‚Üí `Azure Event Hubs`
2. **Connection settings** :
   - Event Hubs namespace : `eh-idoc-flt8076.servicebus.windows.net`
   - Event Hub : `idoc-events`
3. **Connection credentials** :
   - Connection name : `eh-sap-idoc-connection`
   - Authentication kind : `Shared Access Key` ou **Entra ID** (recommand√©)
   - Consumer group : `fabric-consumer`
   - Data format : `JSON`
4. Cliquer `Connect`

#### 3. Ajouter la destination KQL Database
1. Mode Edit ‚Üí `Add destination` ‚Üí `Eventhouse`
2. **Ingestion mode** : `Direct ingestion`
3. **Configuration** :
   - Destination name : `KQL-SAP-Analysis`
   - Workspace : `SAP-IDoc-Fabric`
   - Eventhouse : `kqldbsapidoc_auto`
   - Database : `kqldbsapidoc`
4. Cliquer `Save`

#### 4. Connecter le flux
1. Glisser une connexion de `EventHub-SAP-IDocs` vers `KQL-SAP-Analysis`
2. Cliquer `Publish`

#### 5. Configurer la table KQL
1. En mode Live, cliquer `Configure` dans le n≈ìud destination
2. **Get data** :
   - Table : `New table` ‚Üí `idoc_raw`
   - Data connection name : `es-sap-idoc-connection`
3. **Inspect data** :
   - Format : `JSON`
   - Cr√©er le sch√©ma automatiquement ou manuellement :
     ```kql
     .create table idoc_raw (
         idoc_type: string,
         message_type: string,
         sap_system: string,
         timestamp: datetime,
         control: dynamic,
         data: dynamic,
         raw_payload: string
     )
     ```
4. Cliquer `Finish`

### ‚è±Ô∏è Temps estim√©
15-20 minutes

---

## üéØ Recommandation

| Crit√®re | Option 1 (API) | Option 2 (Import/Export) | Option 3 (Manuel) |
|---------|----------------|--------------------------|-------------------|
| **Automatisation** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê |
| **Facilit√©** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **CI/CD ready** | ‚úÖ | ‚ö†Ô∏è | ‚ùå |
| **Documentation** | ‚ö†Ô∏è Limit√©e | ‚úÖ Compl√®te | ‚úÖ Compl√®te |
| **Maintenance** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |

### Pour un POC / Demo rapide
‚û°Ô∏è **Option 3 (Manuel)** : Configuration en 15 minutes, test imm√©diat

### Pour un d√©ploiement en production
‚û°Ô∏è **Option 1 (API REST)** apr√®s avoir :
1. Configur√© un template manuel pour capturer le sch√©ma JSON
2. Extrait le format exact avec `fab export`
3. Test√© le script `configure-eventstream.ps1`

### Compromis
‚û°Ô∏è **Option 2 (Import/Export)** : Automatisation partielle avec templates versionn√©s

---

## üß™ Test de validation

Apr√®s configuration (quelle que soit l'option), tester le flux complet :

```powershell
# 1. Lancer le simulateur
cd simulator
python main.py

# 2. V√©rifier dans Fabric
# - Eventstream Data Preview montre les messages
# - KQL Database contient les donn√©es

# 3. Requ√™te KQL
idoc_raw
| where timestamp > ago(1h)
| summarize count() by idoc_type
| order by count_ desc
```

---

## üìù Notes importantes

### Authentification Event Hub
- **Shared Access Key** : Fonctionne imm√©diatement, mais moins s√©curis√©
- **Entra ID** (recommand√©) : N√©cessite d'accorder des permissions :
  ```bash
  # Accorder "Azure Event Hubs Data Receiver" √† l'identit√© Fabric
  az role assignment create \
    --role "Azure Event Hubs Data Receiver" \
    --assignee <fabric-managed-identity> \
    --scope /subscriptions/<sub>/resourceGroups/rg-idoc-fabric-dev/providers/Microsoft.EventHub/namespaces/eh-idoc-flt8076
  ```

### Sch√©ma JSON Eventstream
Le format exact des `sources` et `destinations` dans `eventstream.json` n'est **pas officiellement document√©** par Microsoft. L'approche par ing√©nierie inverse (export manuel) est donc n√©cessaire.

### Ressources cr√©√©es
Les 3 options configurent les m√™mes ressources :
- ‚úÖ Source : Azure Event Hub connection
- ‚úÖ Destination : KQL Database avec table `idoc_raw`
- ‚úÖ Flux : EventHub ‚Üí KQL DB (direct ingestion)
- ‚úÖ Mapping : Sch√©ma JSON ‚Üí colonnes KQL

---

## üîó Liens utiles

- [Fabric CLI Documentation](https://microsoft.github.io/fabric-cli/)
- [Eventstream REST API](https://learn.microsoft.com/en-us/rest/api/fabric/eventstream/items)
- [Add Event Hub Source](https://learn.microsoft.com/en-us/fabric/real-time-intelligence/event-streams/add-source-azure-event-hubs)
- [Add KQL Database Destination](https://learn.microsoft.com/en-us/fabric/real-time-intelligence/event-streams/add-destination-kql-database)
